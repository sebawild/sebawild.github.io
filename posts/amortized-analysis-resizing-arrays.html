<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Amortized analysis of resizing-array stacks</title>
  <meta name="description" content="A rigorous proof that a stack implemented with doubling arrays has constant amortized time operations;written up here since it does not seem to appear in any...">

  <link rel="stylesheet" href="/fonts/pagella/stylesheet.css" type="text/css" charset="utf-8" />
  <link rel="stylesheet" href="/fonts/epigrafica/stylesheet.css" type="text/css" charset="utf-8" />
  <link rel="stylesheet" href="/fonts/fontawesome/fontawesome-all.min.css" type="text/css" charset="utf-8" />
  <link rel="stylesheet" href="/fonts/academicons/academicons.min.css" type="text/css" charset="utf-8" />
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://www.wild-inter.net/posts/amortized-analysis-resizing-arrays">
  <link rel="alternate" type="application/rss+xml" title="Sebastian Wild's Site" href="https://www.wild-inter.net/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Sebastian</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#46433A" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#46433A" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#46433A" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/research/">Research</a>
          
        
          
          <a class="page-link" href="/teaching/">Teaching</a>
          
        
          
          <a class="page-link" href="/posts/">Blog</a>
          
        
          
          <a class="page-link" href="/about/">About</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <p class="post-meta">
		<time datetime="2022-10-20T00:00:00+02:00" itemprop="datePublished">
			20 Oct 2022
		</time>
		
	</p>
		 
			
				<a href="/posts/by-categories/#algorithms">
				<p class="post-categories">
					algorithms
				</p>
				</a>
			
				<a href="/posts/by-categories/#teaching">
				<p class="post-categories">
					teaching
				</p>
				</a>
			
		
    <h1 class="post-title" itemprop="name headline">Amortized analysis of resizing-array stacks</h1>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>A rigorous proof that a stack implemented with doubling arrays has constant amortized time operations;
written up here since it does not seem to appear in any of the standard algorithms books.</p>

<script type="text/x-mathjax-config">
	var font = "Neo-Euler";
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [['$','$']],
			displayMath: [['\\[','\\]']],
			processEscapes: true,
		},
		"SVG":{ 
			font:font
		},
		"HTML-CSS": {
			webFont: font,
			imageFont: font,
			preferredFont: font,
			availableFonts: [],
			scale: 85,
			mtextFontInherit: true
		}
	});
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p>A well-known, fundamental data structure is the implementation of a stack 
using resizing arrays (a.k.a. doubling arrays), where we maintain an array of
$C$ items for the $n$ elements of a stack, and whenever the array becomes full, 
we double its size, and whenever the array becomes less that one quarter full,
we halve its size.
This maintains the invariant that $\frac14 C \le n \le C$.</p>

<p>A folklore analysis shows that this achieves constant amortized cost for all
stack operations, despite the occasional expensive resizing operations.</p>

<p>This analysis is not a particularly hard or surprising proof by any means, but it makes a great first nontrivial example
of amortized analysis, and hence I wanted to show it in my <a href="/teaching/comp526"><em>Efficient Algorithms (COMP526)</em></a> lectures;
see <a href="/teaching/comp526/02-fundamental-ds"><em>Unit 2 – Fundamental Data Structures</em></a> for the full context.</p>

<hr />

<p>The goal is to show that while any individual push/pop in a resizing-array based stack might be expensive ($\Omega(n)$ cost), any <em>sequence</em> of operations is necessarily much cheaper, namely $O(1)$ time per operation <strong>on average</strong>.
As the dominant operation, we count array accesses, i.e., any read or write access to an array.</p>

<h2 id="part-1-amortized-costs-for-all-operations">Part 1: Amortized costs for all operations</h2>
<p>Basically, each operation has two types of costs for the amortized analysis: <strong>actual costs</strong> (# array accesses) and a <strong>change in potential/credits</strong>.
We define the potential $\Phi = \min\lbrace n-\frac14C,\;C-n\rbrace$,
and the amortized cost $a_i$ of an operation is the actual cost plus $-4$ times the change in potential.
The intuition behind $\Phi$ is to measure the distance of the current filling mark $n$ from the “expensive boundaries” $\frac14C$ resp. $C$.</p>

<p>We have to analyze both costs separately.</p>

<h3 id="actual-costs">Actual costs:</h3>
<ul>
  <li>cheap push/pop: exactly 1 array access to write/read the topmost element.</li>
  <li>copying push: currently there are $n$ elements on the stack, these have to be read from the old array ($n$ accesses) and written to the new array ($n$ accesses); also one more element has to be added (like in cheap push). In total that is $2n+1$ actual cost.</li>
  <li>
    <p>copying pop: actually exactly the same: there are $n$ elements on the stack, these have to be read from the old array ($n$ accesses) and written to the new array ($n$ accesses); also one element has to be read to be returned. In total that is $2n+1$ actual cost.</p>

    <p>(One could avoid this very last extra read by not copying the element that we pop right after anyways; but typical implementations do not do this for convenience. It would clearly not save much either way.)</p>
  </li>
</ul>

<h3 id="credits--potential-change">Credits / Potential change</h3>
<p>The credits is the <em>change</em> in potential $\Phi = \min\lbrace n-\frac14C,\;C-n\rbrace$.</p>

<ul>
  <li>cheap push: $n$ gets one bigger, but $C$ is unchanged. If $C-n &lt; n-\frac14 C$, then $\Phi$ drops by one (“we lose one credit”).</li>
  <li>cheap pop: $n$ gets one smaller, but $C$ is unchanged. If $n-\frac14 C&lt;C-n$, then $\Phi$ drops by one (“we lose one credit”).</li>
  <li>copying push: We must have had $n=C$ (i.e. $\Phi_{i-1}=0$) before this push, and we will now set $C=2n$ before the push. Then, the push increments $n$. That means the new potential $\Phi_i=(n+1)-\frac14\cdot2n=\frac12n+1$.  We have earned $\frac12n+1$ credits.</li>
  <li>copying pop: We must have had $n=\frac14C$ (i.e. $\Phi_{i-1}=0$) before this push, and we will now make $C=2n$ before the pop; the pop itself then decrements $n$. So $\Phi_i=(n-1)-\frac14\cdot 2n =  \frac12n-1$, and we have earned $\frac12n-1$ credits.</li>
</ul>

<h3 id="adding-up">Adding up</h3>
<p>Adding up actual cost and $-4(\Phi_i-\Phi_{i-1})$ shows that in each case the amortized costs are at most 5.</p>

<h2 id="part-2-from-amortized-to-total-actual-costs">Part 2: From amortized to total actual costs</h2>

<p>The second part is indeed the same for <em>all</em> amortized analyses: The total actual cost over a <em>sequence</em> of $m$ operations is essentially bounded by the sum of their amortized costs, plus initial/final potential; this is shown using a telescoping-sum argument:</p>

\[5m 
\ge \sum_{i=1}^m a_i 
= \sum_{i=1}^m c_i - 
4 \underbrace{\sum_{i=1}^m(\Phi_i - \Phi_{i-1})}_{=\Phi_m - \Phi_0}\]

<p>Rearranging gives</p>

\[\sum_{i=1}^m c_i \le 5m + 4\Phi_m-4\Phi_0\]

<p>Now, we can also show using the invariant $\frac14 C \le n \le C$, i.e.,
$n\le C \le 4n$, that $0\le \Phi\le \frac35n$:
Since $\Phi$ is piecewise linear, it suffices to consider the endpoints of the 
linear segments, i.e., $C = 4n$, $C = n$ and $n-\frac14 C = C-n$, i.e., 
$C = \frac85 n$; at these points $\Phi$ has values $0$, $0$, and $\frac35 n$, respectively.</p>

<p>Hence $\displaystyle\sum_{i=1}^m c_i \le 4\Phi_m -4\Phi_0 \le 5m + 2.4n \in \Theta(m+n)$.</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Sebastian Wild</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <p>Contact:</p>
        <ul class="social-media-list">
          <li><a href="mailto:%73%65%62%61%77%69%6C%64@%67%6D%61%69%6C.%63%6F%6D" title="Contact me">sebawild at gmail</a> ⋅
            <a href="http://pgp.mit.edu/pks/lookup?op=get&search=0x38600ABC14973198">PGP</a></li>
            <li><a href="mailto:%77%69%6C%64@%69%6E%66%6F%72%6D%61%74%69%6B.%75%6E%69-%6D%61%72%62%75%72%67.%64%65" title="Contact me">wild at informatik.uni-marburg.de</a>
              <!-- ⋅ <a href="http://pgp.mit.edu/pks/lookup?op=get&search=0x34EE39A78B149255">PGP</a> --></li>
          <li><a href="mailto:%77%69%6C%64@%6C%69%76%65%72%70%6F%6F%6C.%61%63.%75%6B" title="Contact me">wild at liverpool.ac.uk</a> ⋅
            <a href="http://pgp.mit.edu/pks/lookup?op=get&search=0x34EE39A78B149255">PGP</a></li>

              <p>  </p>
          <li><del><a href="mailto:%77%69%6C%64@%75%77%61%74%65%72%6C%6F%6F.%63%61" title="Contact me">wild at uwaterloo.ca</a></del> ⋅
            <a href="http://pgp.mit.edu/pks/lookup?op=get&search=0x34EE39A78B149255">PGP</a></li>
          <li><del><a href="mailto:%77%69%6C%64@%63%73.%75%6E%69-%6B%6C.%64%65" title="Contact me">wild at cs.uni-kl.de</a></del></li>
          <p>  </p>
          <li><a href="https://www.uni-marburg.de/de/fb12/arbeitsgruppen/algorith/team/sebastian-wild">Website at UMR</a></li>
          <li><a href="https://www.liverpool.ac.uk/computer-science/staff/sebastian-wild">Website at UoL</a></li>
          <li><a href="https://www.csc.liv.ac.uk/~swild">intranet site at UoL</a></li>
          <li><a href="https://tcs.csc.liv.ac.uk">TCS @ Liverpool</a></li>
          <li><del><a href="http://wwwagak.cs.uni-kl.de/home/staff/sebastian-wild">(Old) website TU KL</a></del></li>

          

          
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <p>Elsewhere:</p>
        <ul class="contact-list">
          <li><a href="https://github.com/sebawild" title="GitHub sebawild"><i class="fab fa-github"></i> GitHub sebawild</a></li>
          <li><a href="https://www.linkedin.com/in/sebastian-wild-liverpool/"><i class="fab fa-linkedin"></i> LinkedIn profile</a></li>
          <li><a rel="me" href="https://mathstodon.xyz/@wild" title="Mastodon @wild@mathstodon.xyz" ><i class="fab fa-mastodon"></i> @wild@mathstodon.xyz</a></li>
          <li><del><a href="https://twitter.com/Sebastian_Wild_" title="Twitter @Sebastian_Wild_"><i class="fab fa-twitter"></i> @Sebastian_Wild_</a></del></li>
          <li><a href="https://bsky.app/profile/sebastianwild.bsky.social" title="Bluesky @sebastianwild.bsky.social">🦋 @sebastianwild</a></li>
          
          <p>  </p>
          <li><a href="http://orcid.org/0000-0002-6061-9177" title="ORCID: 0000-0002-6061-9177"><i class="ai ai-orcid"></i> 0000-0002-6061-9177</a></li>
          <li><a href="https://scholar.google.de/citations?user=aMyZiK0AAAAJ"><i class="ai ai-google-scholar"></i>
 Google Scholar profile</a></li>
          <li><a href="http://dblp.uni-trier.de/pers/hd/w/Wild:Sebastian"><i class="ai ai-dblp"></i> DBLP publication list</a></li>
          <li><a href="https://www.semanticscholar.org/author/3124206"><i class="ai ai-semantic-scholar"></i> Semantic Scholar Author Page</a></li>
          <li><a href="http://arxiv.org/a/wild_s_2"><i class="ai ai-arxiv"></i> arXiv Author ID</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Quick links:</p>
        <ul style="margin-top: -1.5ex;">
          <li><a href="/publications">my publications</a></li>
          <li><a href="https://disk.wild-inter.net:5001/fbsharing/J0v0S8yF">my library</a></li>
        </ul>
      </div>
    </div>
  </div>
</footer>


  </body>

</html>
